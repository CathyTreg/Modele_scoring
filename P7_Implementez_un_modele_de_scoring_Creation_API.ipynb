{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4091d6a1-923e-4cc8-8473-3720d127ee21",
   "metadata": {},
   "source": [
    "# Projet P7 : Implémentez un modèle de scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56988b46-ea6f-4ead-a5aa-0ea837867ceb",
   "metadata": {},
   "source": [
    "## Contexte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe789e6-27cf-4a44-9615-592a9fbf6b59",
   "metadata": {},
   "source": [
    "Vous êtes Data Scientist au sein d'une société financière, nommée \"Prêt à dépenser\", qui propose des crédits à la consommation pour des personnes ayant peu ou pas du tout d'historique de prêt.\n",
    "\n",
    "L’entreprise souhaite mettre en œuvre un outil de “scoring crédit” pour calculer la probabilité qu’un client rembourse son crédit, puis classifie la demande en crédit accordé ou refusé. Elle souhaite donc développer un algorithme de classification en s’appuyant sur des sources de données variées (données comportementales, données provenant d'autres institutions financières, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290a6b0c-b3a8-4ac2-bda0-85b2d3d81a3a",
   "metadata": {},
   "source": [
    "<b> MISSION : </b>\n",
    "\n",
    "Construire un modèle de scoring qui donnera une prédiction sur la probabilité de faillite d'un client de façon automatique.\n",
    "\n",
    "Analyser les features qui contribuent le plus au modèle, d’une manière générale (feature importance globale) et au niveau d’un client (feature importance locale), afin, dans un soucis de transparence, de permettre à un chargé d’études de mieux comprendre le score attribué par le modèle.\n",
    "\n",
    "Mettre en production le modèle de scoring de prédiction à l’aide d’une API et réaliser une interface de test de cette API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8d1755-d4c5-4e8d-95bb-ac8e99ca9462",
   "metadata": {},
   "source": [
    "<b> Approche MLOps : </b>\n",
    "\n",
    "Afin de pouvoir faire évoluer régulièrement le modèle, mettre en œuvre une démarche de type MLOps d’automatisation et d’industrialisation de la gestion du cycle de vie du modèle (du tracking des expérimentations à l’analyse en production du data drift). \n",
    "\n",
    "Mettre en oeuvre au minimum les étapes orientées MLOps suivantes : \n",
    "\n",
    "- Dans le notebook d’entraînement des modèles, générer à l’aide de MLFlow un tracking d'expérimentations\n",
    "- Lancer l’interface web 'UI MLFlow\" d'affichage des résultats du tracking\n",
    "- Réaliser avec MLFlow un stockage centralisé des modèles dans un “model registry”\n",
    "- Tester le serving MLFlow\n",
    "- Gérer le code avec le logiciel de version Git\n",
    "- Partager le code sur Github pour assurer une intégration continue\n",
    "- Utiliser Github Actions pour le déploiement continu et automatisé du code de l’API sur le cloud\n",
    "- Concevoir des tests unitaires avec Pytest (ou Unittest) et les exécuter de manière automatisée lors du build réalisé par Github Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d1c263-8475-4d31-9122-c203550a6da6",
   "metadata": {},
   "source": [
    "<b> Elaboration du modèle : </b>\n",
    "\n",
    "Attention à deux points spécifiques au contexte métier : \n",
    "\n",
    "- Le déséquilibre entre le nombre de bons et de moins bons clients doit être pris en compte pour élaborer un modèle pertinent, avec une méthode au choix\n",
    "- Le déséquilibre du coût métier entre un faux négatif (FN - mauvais client prédit bon client : donc crédit accordé et perte en capital) et un faux positif (FP - bon client prédit mauvais : donc refus crédit et manque à gagner en marge). Vous pourrez supposer, par exemple, que le coût d’un FN est dix fois supérieur au coût d’un FP. Vous créerez un score “métier” (minimisation du coût d’erreur de prédiction des FN et FP) pour comparer les modèles, afin de choisir le meilleur modèle et ses meilleurs hyperparamètres. Attention cette minimisation du coût métier doit passer par l’optimisation du seuil qui détermine, à partir d’une probabilité, la classe 0 ou 1 (un “predict” suppose un seuil à 0.5 qui n’est pas forcément l’optimum). En parallèle, maintenez pour comparaison et contrôle des mesures plus techniques, telles que l’AUC et l’accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5a2044-baa3-4160-b77c-c653c2040b87",
   "metadata": {},
   "source": [
    "## Etapes du projet :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d0d90-895c-480c-b6ff-65d7f9aa2acc",
   "metadata": {},
   "source": [
    "Elaboration d'un modèle de prédiction sous forme d’une API qui permet de calculer la probabilité de défaut du client, ainsi que sa classe (accepté ou refusé), déployer l'API sur une plateforme Cloud.\n",
    "\n",
    "- <b> Etape préliminaire : </b> Importation des données ( --> NoteBook1 : Preprocessing )\n",
    "- <b> Etape 1 : </b> EDA sur la table principale application ( --> NoteBook1 : Preprocessing ) \n",
    "- <b> Etape 2 : </b> Ajout des tables bureau et bureau_balance ( --> NoteBook1 : Preprocessing)\n",
    "- <b> Etape 3 : </b> Ajout des tables previous_application, POS_CASH_balance, installments_payments et credit_card_balance ( --> NoteBook1 : Preprocessing)\n",
    "- <b> Etape 4 : </b> Feature selection, feature engineering ( --> NoteBook1 : Preprocessing)\n",
    "- <b> Etape 5 : </b> Elaboration des modèles avec un tracking d'expérimentations ( --> NoteBook2 : MLFlow_Modeles)\n",
    "- <b> Etape 6 : </b> Création de l'API et des tests unitaires ( --> NoteBook3 : Creation_API & scripts app.py et test_api.py)\n",
    "- <b> Etape 7 : </b> Déploiement de l’API sur une plateforme Cloud (Azure)\n",
    "- <b> Etape 8 : </b> Analyse du Data Drift (--> NoteBook4 : DataDRIFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c7299e-f8da-4c42-8efb-5b25ee762f7f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04e8eb94-9d84-480e-92ef-fb86cd10f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn methods\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "\n",
    "# Outils MLOps\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66d4cc-8e14-4966-ade3-98b28e6b7139",
   "metadata": {},
   "source": [
    "## ETAPE 6 : Création de l'API\n",
    "\n",
    "ETAPE 6 : Création d'un fichier .py séparé pour notre application Flask = ce fichier importera le modèle et définira les endpoints pour prédire les résultats.\n",
    "    \n",
    "    1. Importer les données clients à prédire \n",
    "    2. Transformer les données \n",
    "        - standardisation \n",
    "        - imputation\n",
    "    3. Création de l'API avec Flask (fichier python app.py)\n",
    "    4. Intéroger l'API en local \n",
    "    5. Intéroger l'API sur le web\n",
    "    6. Mettre en place un test de l'API avec unittest (fichier python test_api.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfabd32-a1fc-4f1b-b047-2f73fe421f04",
   "metadata": {},
   "source": [
    "### 1. Importer les données clients à prédire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b119df6-ec25-4946-9de7-37a14466fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_client = pd.read_csv('./data/test_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b57fe4b-2b5d-44dc-b58e-527c3fc99b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner un échantillon aléatoire de 100 clients pour commiter le fichier (github)\n",
    "subset_clients = data_client.sample(n=100, random_state=42)\n",
    "subset_clients.to_csv('./data/subset_clients.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24e0b115-9276-4bac-b01e-cdb6d662efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_clients.set_index('SK_ID_CURR', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12e4aa06-a48f-4dbc-aa4a-a4c287886c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 276)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_clients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "773421df-bc61-4134-b7ad-0b94de909393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les noms des colonnes avant transformation\n",
    "column_names = subset_clients.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e4af34-cd94-4d44-b8b9-eb067f8ae5ed",
   "metadata": {},
   "source": [
    "### 2. Transformer les données "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e15284-a1f0-40e3-8a35-0550779913b0",
   "metadata": {},
   "source": [
    "#### -- Standardiser --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c5af0f6-3767-4185-a84e-1a9233d7b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(subset_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aea089-6e70-429e-a673-54bc4a11d768",
   "metadata": {},
   "source": [
    "#### -- Imputer les valeurs manquantes --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2e7afec-1dca-43e8-a788-ddd1a20f0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une instance de SimpleImputer avec la stratégie 'median'\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Appliquer l'imputer sur X_scaled\n",
    "X_scaled_imputed = imputer.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4968c247-9a9a-4732-b202-dca1955855bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer X_scaled_imputed en DataFrame et récupérer les colonnes d'origine\n",
    "X_scaled_imputed_df = pd.DataFrame(X_scaled_imputed, index=subset_clients.index, columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f68d9-984b-4ea1-8a61-90327f9201a2",
   "metadata": {},
   "source": [
    "### 3. Création de l'API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a8bb1-ede2-47fd-aa81-866832290374",
   "metadata": {},
   "source": [
    "Cette partie n'est pas exécutée ici mais dans un script app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a658fe-60e4-449d-872c-cbd30814ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester l'API en local\n",
    "# Pour le fichier app.py il faudra modifier l'url et le chemin du read.csv\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "import joblib\n",
    "from flask import Flask, jsonify, request\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from utils_fonction_cout import cout_metier\n",
    "from utils_threshold import find_best_threshold\n",
    "\n",
    "\n",
    "# Importer les données clients à prédire \n",
    "data_client = pd.read_csv('./data/subset_clients.csv')\n",
    "# mettre la colonne id client en index\n",
    "data_client.set_index('SK_ID_CURR', inplace=True)\n",
    "# Sauvegarder les noms des colonnes avant transformation\n",
    "column_names = data_client.columns\n",
    "\n",
    "# Transformer les données - centrer et réduire\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(data_client)\n",
    "\n",
    "# Transformer les données - Imputer les valeurs manquantes avec la stratégie 'median'\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_scaled_imputed = imputer.fit_transform(X_scaled)\n",
    "\n",
    "# Transformer X_scaled_imputed en DataFrame et récupérer les colonnes d'origine\n",
    "X_scaled_imputed_df = pd.DataFrame(X_scaled_imputed, index=data_client.index, columns=column_names)\n",
    "\n",
    "# Charger le modèle \n",
    "logistic_model = joblib.load('logistic_model.pkl')\n",
    "\n",
    "# Initialiser l'application Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Définir un endpoint pour la prédiction\n",
    "@app.route('/predict', methods=['GET'])\n",
    "def predict():\n",
    "    # Récupérer le client_id depuis les paramètres de la requête\n",
    "    client_id = request.args.get('client_id', type=int)\n",
    "    \n",
    "    if client_id is None:\n",
    "        return jsonify({\"error\": \"client_id manquant ou invalide\"}), 400\n",
    "    \n",
    "    # Récupérer les données du client\n",
    "    client = X_scaled_imputed_df.loc[client_id]\n",
    "    \n",
    "    # Extraire les caractéristiques et les convertir en tableau NumPy\n",
    "    features = np.array(client).reshape(1, -1)\n",
    "    \n",
    "    # Faire une prédiction de défaut de paiement\n",
    "    prediction = logistic_model.predict(features)\n",
    "    \n",
    "    # Vérifier le résultat de la prédiction et retourner le message approprié\n",
    "    result = \"credit accepte\" if int(prediction[0]) == 0 else \"credit refuse\"\n",
    "    \n",
    "    # La probabilité de défaut\n",
    "    probability_class_1 = logistic_model.predict_proba(features)[:, 1]\n",
    "    \n",
    "    # Convertir la probabilité en liste pour JSON\n",
    "    probability_class_1_list = probability_class_1.tolist()\n",
    "    \n",
    "    # Retourner le résultat sous forme de JSON\n",
    "    return jsonify({\n",
    "        'client_id': client_id,\n",
    "        'probabilite_defaut (seuil=0.5)': probability_class_1_list,\n",
    "        'prediction': result\n",
    "    })\n",
    "\n",
    "# Définir un endpoint de test pour s'assurer que l'API fonctionne\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    return \"API de prédiction de régression logistique est opérationnelle!\"\n",
    "\n",
    "# Lancer l'application Flask\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af10be8-3c3f-4292-acea-6ddfb962bd4f",
   "metadata": {},
   "source": [
    "### 4. Intéroger l'API en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e6b6781e-6277-4761-a507-0d29053b76bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'client_id': 418609, 'prediction': 'credit accepte', 'probabilite_defaut (seuil=0.5)': [0.22180146978918214]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://127.0.0.1:5000/predict?client_id=418609'\n",
    "\n",
    "# Utiliser requests.get() pour envoyer une requête GET\n",
    "response = requests.get(url)\n",
    "\n",
    "# Afficher la réponse JSON\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c095cc57-4b98-4d1e-be15-bb0b5690d100",
   "metadata": {},
   "source": [
    "### 5. Intéroger l'API sur le web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b4c6e94a-ad72-4a65-b055-914e731aa841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'client_id': 398791, 'prediction': 'credit refuse', 'probabilite_defaut (seuil=0.5)': [0.9061315323273397]}\n"
     ]
    }
   ],
   "source": [
    "# Après déploiement de l'API\n",
    "# Liste de clients pour test (acceptés) : 291599, 418609, 202661, 185171, 111761, 258225, 174954, 297336, 369893, 195695, 384221, 203868, 182895\n",
    "# Liste de clients pour test (refusés) : 362707, 398791, 195695\n",
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://webappscoringcredit-gcbhe8axc2exdfge.francecentral-01.azurewebsites.net/predict?client_id=398791'\n",
    "\n",
    "# Utiliser requests.get() pour envoyer une requête GET\n",
    "response = requests.get(url)\n",
    "\n",
    "# Afficher la réponse JSON\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07567050-1dc5-42e6-9dbb-eb680078c47f",
   "metadata": {},
   "source": [
    "### 6. Mettre en place un test de l'API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f14c9-d270-4191-90fb-8b8c4e21f3ee",
   "metadata": {},
   "source": [
    "Cette partie n'est pas exécutée ici mais dans un script test_api.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ca0f6-db8d-4b4e-9ced-a19b55703e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester l'API en local\n",
    "# Pour le fichier test_api.py il faudra modifier l'url et le chemin du read.csv\n",
    "\n",
    "import unittest\n",
    "import requests\n",
    "\n",
    "# URL de ton API\n",
    "BASE_API_URL = \"http://127.0.0.1:5000/predict\"\n",
    "\n",
    "class TestPredictAPI(unittest.TestCase):\n",
    "        \n",
    "    def test_predict_random_client(self):\n",
    "        \"\"\"Test de prédiction pour un client du fichier\"\"\"\n",
    "        id_client = 144092  # Test pour un id_client\n",
    "        url = f\"{BASE_API_URL}?client_id={id_client}\"  # Construire l'URL avec le paramètre client_id\n",
    "        \n",
    "        # Envoyer une requête GET à l'API\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Vérifie que la requête a réussi\n",
    "        self.assertEqual(response.status_code, 200)\n",
    "        \n",
    "        # Vérifie que la réponse est au format JSON et contient les clés appropriées\n",
    "        response_data = response.json()\n",
    "        self.assertIn('client_id', response_data)\n",
    "        self.assertIn('probabilite_defaut (seuil=0.5)', response_data)\n",
    "        self.assertIn('prediction', response_data)\n",
    "        \n",
    "        # Vérifie que la prédiction est soit \"crédit accepté\", soit \"crédit refusé\"\n",
    "        prediction = response_data['prediction']\n",
    "        self.assertIn(prediction, [\"credit accepte\", \"credit refuse\"])\n",
    "        \n",
    "        # Vérifie que 'probabilite_defaut (seuil=0.5)' est une liste de nombres\n",
    "        self.assertIsInstance(response_data['probabilite_defaut (seuil=0.5)'], list)\n",
    "        self.assertTrue(all(isinstance(x, float) for x in response_data['probabilite_defaut (seuil=0.5)']))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel Formation_P7",
   "language": "python",
   "name": "formation_p7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
