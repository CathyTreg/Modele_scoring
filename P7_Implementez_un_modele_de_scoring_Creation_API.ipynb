{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4091d6a1-923e-4cc8-8473-3720d127ee21",
   "metadata": {},
   "source": [
    "# Projet P7 : Implémentez un modèle de scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56988b46-ea6f-4ead-a5aa-0ea837867ceb",
   "metadata": {},
   "source": [
    "## Contexte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe789e6-27cf-4a44-9615-592a9fbf6b59",
   "metadata": {},
   "source": [
    "Vous êtes Data Scientist au sein d'une société financière, nommée \"Prêt à dépenser\", qui propose des crédits à la consommation pour des personnes ayant peu ou pas du tout d'historique de prêt.\n",
    "\n",
    "L’entreprise souhaite mettre en œuvre un outil de “scoring crédit” pour calculer la probabilité qu’un client rembourse son crédit, puis classifie la demande en crédit accordé ou refusé. Elle souhaite donc développer un algorithme de classification en s’appuyant sur des sources de données variées (données comportementales, données provenant d'autres institutions financières, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290a6b0c-b3a8-4ac2-bda0-85b2d3d81a3a",
   "metadata": {},
   "source": [
    "<b> MISSION 1 : </b>\n",
    "\n",
    "Construire un modèle de scoring qui donnera une prédiction sur la probabilité de faillite d'un client de façon automatique.\n",
    "\n",
    "Analyser les features qui contribuent le plus au modèle, d’une manière générale (feature importance globale) et au niveau d’un client (feature importance locale), afin, dans un soucis de transparence, de permettre à un chargé d’études de mieux comprendre le score attribué par le modèle.\n",
    "\n",
    "Mettre en production le modèle de scoring de prédiction à l’aide d’une API et réaliser une interface de test de cette API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8d1755-d4c5-4e8d-95bb-ac8e99ca9462",
   "metadata": {},
   "source": [
    "<b> Approche MLOps : </b>\n",
    "\n",
    "Afin de pouvoir faire évoluer régulièrement le modèle, mettre en œuvre une démarche de type MLOps d’automatisation et d’industrialisation de la gestion du cycle de vie du modèle (du tracking des expérimentations à l’analyse en production du data drift). \n",
    "\n",
    "Mettre en oeuvre au minimum les étapes orientées MLOps suivantes : \n",
    "\n",
    "- Dans le notebook d’entraînement des modèles, générer à l’aide de MLFlow un tracking d'expérimentations\n",
    "- Lancer l’interface web 'UI MLFlow\" d'affichage des résultats du tracking\n",
    "- Réaliser avec MLFlow un stockage centralisé des modèles dans un “model registry”\n",
    "- Tester le serving MLFlow\n",
    "- Gérer le code avec le logiciel de version Git\n",
    "- Partager le code sur Github pour assurer une intégration continue\n",
    "- Utiliser Github Actions pour le déploiement continu et automatisé du code de l’API sur le cloud\n",
    "- Concevoir des tests unitaires avec Pytest (ou Unittest) et les exécuter de manière automatisée lors du build réalisé par Github Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d1c263-8475-4d31-9122-c203550a6da6",
   "metadata": {},
   "source": [
    "<b> Elaboration du modèle : </b>\n",
    "\n",
    "Attention à deux points spécifiques au contexte métier : \n",
    "\n",
    "- Le déséquilibre entre le nombre de bons et de moins bons clients doit être pris en compte pour élaborer un modèle pertinent, avec une méthode au choix\n",
    "- Le déséquilibre du coût métier entre un faux négatif (FN - mauvais client prédit bon client : donc crédit accordé et perte en capital) et un faux positif (FP - bon client prédit mauvais : donc refus crédit et manque à gagner en marge). Vous pourrez supposer, par exemple, que le coût d’un FN est dix fois supérieur au coût d’un FP. Vous créerez un score “métier” (minimisation du coût d’erreur de prédiction des FN et FP) pour comparer les modèles, afin de choisir le meilleur modèle et ses meilleurs hyperparamètres. Attention cette minimisation du coût métier doit passer par l’optimisation du seuil qui détermine, à partir d’une probabilité, la classe 0 ou 1 (un “predict” suppose un seuil à 0.5 qui n’est pas forcément l’optimum). En parallèle, maintenez pour comparaison et contrôle des mesures plus techniques, telles que l’AUC et l’accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5a2044-baa3-4160-b77c-c653c2040b87",
   "metadata": {},
   "source": [
    "## Etapes du projet :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d0d90-895c-480c-b6ff-65d7f9aa2acc",
   "metadata": {},
   "source": [
    "Elaboration d'un modèle de prédiction sous forme d’une API qui permet de calculer la probabilité de défaut du client, ainsi que sa classe (accepté ou refusé), déployer l'API sur une plateforme Cloud.\n",
    "\n",
    "- <b> Etape préliminaire : </b> Importation des données ( --> NoteBook1 : Preparation des données )\n",
    "- <b> Etape 1 : </b> EDA et feature engineering sur la table principale application ( --> NoteBook1 ) \n",
    "- <b> Etape 2 : </b> Ajout des tables bureau et bureau_balance ( --> NoteBook1 )\n",
    "- <b> Etape 3 : </b> Ajout des tables previous_application, POS_CASH_balance, installments_payments et credit_card_balance ( --> NoteBook1 )\n",
    "\n",
    "- <b> Etape 4 : </b> EDA et Feature selection, feature engineering ( --> NoteBook1 )\n",
    "\n",
    "- <b> Etape 5 : </b> Elaboration des modèles avec un tracking d'expérimentations (avec Cross-Validation et optimisation des hyperparamètres, via GridsearchCV ou équivalent)\n",
    "- <b> Etape 6 : </b> Création de l'API (Notebook ou une application Streamlit pour réaliser en local l’interface de test de l’API)\n",
    "- <b> Etape 7 : </b> Déploiement de l’API sur une plateforme Cloud (de préférence une solution gratuite)\n",
    "- <b> Etape 8 : </b> Analyse du Data Drift (evidently)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c7299e-f8da-4c42-8efb-5b25ee762f7f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04e8eb94-9d84-480e-92ef-fb86cd10f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn methods\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "\n",
    "# Outils MLOps\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66d4cc-8e14-4966-ade3-98b28e6b7139",
   "metadata": {},
   "source": [
    "## ETAPE 6 : Création de l'API\n",
    "\n",
    "ETAPE 6 : Création d'un fichier .py séparé pour notre application Flask = ce fichier importera le modèle et définira les endpoints pour prédire les résultats.\n",
    "    \n",
    "    1. Importer les données clients à prédire \n",
    "    2. Transformer les données \n",
    "        - standardisation \n",
    "        - imputation\n",
    "    3. Application Flask - fichier python\n",
    "    4. Intéroger l'API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfabd32-a1fc-4f1b-b047-2f73fe421f04",
   "metadata": {},
   "source": [
    "### 1. Importer les données clients à prédire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b119df6-ec25-4946-9de7-37a14466fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_client = pd.read_csv('./data/test_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2257f1-6eda-4d14-b3e6-64b0b68c6572",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_client = data_client.drop(columns = ['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e4aa06-a48f-4dbc-aa4a-a4c287886c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 276)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_client.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e4af34-cd94-4d44-b8b9-eb067f8ae5ed",
   "metadata": {},
   "source": [
    "### 2. Transformer les données "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e15284-a1f0-40e3-8a35-0550779913b0",
   "metadata": {},
   "source": [
    "#### -- Standardiser --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c5af0f6-3767-4185-a84e-1a9233d7b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(data_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aea089-6e70-429e-a673-54bc4a11d768",
   "metadata": {},
   "source": [
    "#### -- Imputer les valeurs manquantes --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2e7afec-1dca-43e8-a788-ddd1a20f0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une instance de SimpleImputer avec la stratégie 'median'\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Appliquer l'imputer sur X_scaled\n",
    "X_scaled_imputed = imputer.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f68d9-984b-4ea1-8a61-90327f9201a2",
   "metadata": {},
   "source": [
    "### 3. Création de l'API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a8bb1-ede2-47fd-aa81-866832290374",
   "metadata": {},
   "source": [
    "Cette partie n'est pas exécutée ici mais dans un script app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "edb4e04e-9e3a-4eea-ba7e-5b2ff52a5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cout_metier(y_true, y_pred):\n",
    "    \"\"\"Cette fonction calcule le coût métier à partir de la matrice de confusion : 10*FN + FP.\"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return 10 * fn + fp\n",
    "\n",
    "cout_metier_scorer = make_scorer(cout_metier, greater_is_better=False)\n",
    "\n",
    "def find_best_threshold(estimator, X, y):\n",
    "    \"\"\"Cette fonction trouve le seuil optimal en testant une gamme de seuils et en choisissant celui avec le score métier le plus bas.\"\"\"\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "    best_threshold, best_score = 0, float('inf')\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (estimator.predict_proba(X)[:, 1] >= threshold).astype(int)\n",
    "        score = cout_metier(y, y_pred)\n",
    "        if score < best_score:\n",
    "            best_threshold, best_score = threshold, score\n",
    "    return best_threshold, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c977ff21-fffe-4a6b-be08-282579864cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle\n",
    "model = joblib.load('modele_logRegression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9d645575-6b17-4743-8ccf-0732c2a9c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer le meilleur modèle et la partie classification\n",
    "best_model = model.best_estimator_\n",
    "logistic_model = best_model.named_steps['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a658fe-60e4-449d-872c-cbd30814ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser l'application Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Définir un endpoint pour la prédiction\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Récupérer les données envoyées dans la requête POST\n",
    "    data = request.get_json(force=True)\n",
    "    \n",
    "    # Extraire les caractéristiques et les convertir en tableau NumPy\n",
    "    features = np.array(data).reshape(1, -1)\n",
    "    \n",
    "    # Faire une prédiction\n",
    "    prediction = logistic_model.predict(features)\n",
    "    \n",
    "    # Vérifier le résultat de la prédiction et retourner le message approprié\n",
    "    result = \"crédit accepté\" if int(prediction[0]) == 0 else \"crédit refusé\"\n",
    "    \n",
    "    # Retourner le résultat sous forme de JSON\n",
    "    return jsonify({'prediction': result})\n",
    "\n",
    "# Définir un endpoint de test pour s'assurer que l'API fonctionne\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    return \"API de prédiction de régression logistique est opérationnelle!\"\n",
    "\n",
    "# Lancer l'application Flask\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af10be8-3c3f-4292-acea-6ddfb962bd4f",
   "metadata": {},
   "source": [
    "### 4. Intéroger l'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2f69b94-e273-4ff3-80ef-9b2533031349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectionner un client :\n",
    "client = X_scaled_imputed [1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6b6781e-6277-4761-a507-0d29053b76bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 'crédit refusé'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://127.0.0.1:5000/predict'\n",
    "data = client.tolist()\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2030b13e-1c9f-449b-8381-26c303d04230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel Formation_P7",
   "language": "python",
   "name": "formation_p7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
