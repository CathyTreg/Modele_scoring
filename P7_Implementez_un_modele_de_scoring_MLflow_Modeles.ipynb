{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet P7 : Impl√©mentez un mod√®le de scoring - Mod√®les"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous √™tes Data Scientist au sein d'une soci√©t√© financi√®re, nomm√©e \"Pr√™t √† d√©penser\", qui propose des cr√©dits √† la consommation pour des personnes ayant peu ou pas du tout d'historique de pr√™t.\n",
    "\n",
    "L‚Äôentreprise souhaite mettre en ≈ìuvre un outil de ‚Äúscoring cr√©dit‚Äù pour calculer la probabilit√© qu‚Äôun client rembourse son cr√©dit, puis classifie la demande en cr√©dit accord√© ou refus√©. Elle souhaite donc d√©velopper un algorithme de classification en s‚Äôappuyant sur des sources de donn√©es vari√©es (donn√©es comportementales, donn√©es provenant d'autres institutions financi√®res, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> MISSION 1 : </b>\n",
    "\n",
    "Construire un mod√®le de scoring qui donnera une pr√©diction sur la probabilit√© de faillite d'un client de fa√ßon automatique.\n",
    "\n",
    "Analyser les features qui contribuent le plus au mod√®le, d‚Äôune mani√®re g√©n√©rale (feature importance globale) et au niveau d‚Äôun client (feature importance locale), afin, dans un soucis de transparence, de permettre √† un charg√© d‚Äô√©tudes de mieux comprendre le score attribu√© par le mod√®le.\n",
    "\n",
    "Mettre en production le mod√®le de scoring de pr√©diction √† l‚Äôaide d‚Äôune API et r√©aliser une interface de test de cette API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Approche MLOps : </b>\n",
    "\n",
    "Afin de pouvoir faire √©voluer r√©guli√®rement le mod√®le, mettre en ≈ìuvre une d√©marche de type MLOps d‚Äôautomatisation et d‚Äôindustrialisation de la gestion du cycle de vie du mod√®le (du tracking des exp√©rimentations √† l‚Äôanalyse en production du data drift). \n",
    "\n",
    "Mettre en oeuvre au minimum les √©tapes orient√©es MLOps suivantes : \n",
    "\n",
    "- Dans le notebook d‚Äôentra√Ænement des mod√®les, g√©n√©rer √† l‚Äôaide de MLFlow un tracking d'exp√©rimentations\n",
    "- Lancer l‚Äôinterface web 'UI MLFlow\" d'affichage des r√©sultats du tracking\n",
    "- R√©aliser avec MLFlow un stockage centralis√© des mod√®les dans un ‚Äúmodel registry‚Äù\n",
    "- Tester le serving MLFlow\n",
    "- G√©rer le code avec le logiciel de version Git\n",
    "- Partager le code sur Github pour assurer une int√©gration continue\n",
    "- Utiliser Github Actions pour le d√©ploiement continu et automatis√© du code de l‚ÄôAPI sur le cloud\n",
    "- Concevoir des tests unitaires avec Pytest (ou Unittest) et les ex√©cuter de mani√®re automatis√©e lors du build r√©alis√© par Github Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Elaboration du mod√®le : </b>\n",
    "\n",
    "Attention √† deux points sp√©cifiques au contexte m√©tier : \n",
    "\n",
    "- Le d√©s√©quilibre entre le nombre de bons et de moins bons clients doit √™tre pris en compte pour √©laborer un mod√®le pertinent, avec une m√©thode au choix\n",
    "- Le d√©s√©quilibre du co√ªt m√©tier entre un faux n√©gatif (FN - mauvais client pr√©dit bon client : donc cr√©dit accord√© et perte en capital) et un faux positif (FP - bon client pr√©dit mauvais : donc refus cr√©dit et manque √† gagner en marge). Vous pourrez supposer, par exemple, que le co√ªt d‚Äôun FN est dix fois sup√©rieur au co√ªt d‚Äôun FP. Vous cr√©erez un score ‚Äúm√©tier‚Äù (minimisation du co√ªt d‚Äôerreur de pr√©diction des FN et FP) pour comparer les mod√®les, afin de choisir le meilleur mod√®le et ses meilleurs hyperparam√®tres. Attention cette minimisation du co√ªt m√©tier doit passer par l‚Äôoptimisation du seuil qui d√©termine, √† partir d‚Äôune probabilit√©, la classe 0 ou 1 (un ‚Äúpredict‚Äù suppose un seuil √† 0.5 qui n‚Äôest pas forc√©ment l‚Äôoptimum). En parall√®le, maintenez pour comparaison et contr√¥le des mesures plus techniques, telles que l‚ÄôAUC et l‚Äôaccuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernels Kaggle utilis√©s pour l‚Äôanalyse exploratoire, la pr√©paration des donn√©es et le feature engineering :\n",
    "    \n",
    "    - https://www.kaggle.com/code/willkoehrsen/start-here-a-gentle-introduction/notebook\n",
    "    - https://www.kaggle.com/code/willkoehrsen/introduction-to-manual-feature-engineering\n",
    "    - https://www.kaggle.com/code/willkoehrsen/introduction-to-manual-feature-engineering-p2\n",
    "    - https://www.kaggle.com/code/willkoehrsen/introduction-to-feature-selection\n",
    "    \n",
    "    - https://www.kaggle.com/code/jsaguiar/lightgbm-with-simple-features/script --> pas utilis√© pour le moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapes du projet :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elaboration d'un mod√®le de pr√©diction sous forme d‚Äôune API qui permet de calculer la probabilit√© de d√©faut du client, ainsi que sa classe (accept√© ou refus√©), d√©ployer l'API sur une plateforme Cloud.\n",
    "\n",
    "- <b> Etape pr√©liminaire : </b> Importation des donn√©es ( --> NoteBook1 : Preparation des donn√©es )\n",
    "- <b> Etape 1 : </b> EDA et feature engineering sur la table principale application ( --> NoteBook1 ) \n",
    "- <b> Etape 2 : </b> Ajout des tables bureau et bureau_balance ( --> NoteBook1 )\n",
    "- <b> Etape 3 : </b> Ajout des tables previous_application, POS_CASH_balance, installments_payments et credit_card_balance ( --> NoteBook1 )\n",
    "\n",
    "- <b> Etape 4 : </b> EDA et Feature selection, feature engineering ( --> NoteBook1 )\n",
    "\n",
    "- <b> Etape 5 : </b> Elaboration des mod√®les avec un tracking d'exp√©rimentations (avec Cross-Validation et optimisation des hyperparam√®tres, via GridsearchCV ou √©quivalent)\n",
    "- <b> Etape 6 : </b> Cr√©ation de l'API (Notebook ou une application Streamlit pour r√©aliser en local l‚Äôinterface de test de l‚ÄôAPI)\n",
    "- <b> Etape 7 : </b> D√©ploiement de l‚ÄôAPI sur une plateforme Cloud (de pr√©f√©rence une solution gratuite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d632b08c-d252-4238-b496-e2c6edebec4b",
    "_uuid": "eb13bf76d4e1e60d0703856ec391cdc2c5bdf1fb"
   },
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn methods\n",
    "from sklearn.metrics import make_scorer, roc_curve, roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Donn√©es d√©s√©quilibr√©es\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Models\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Outils MLOps\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAPE 5 : Elaboration des mod√®les avec un tracking d'exp√©rimentations\n",
    "\n",
    "ETAPE 5\n",
    "    \n",
    "    1. Pr√©parer les donn√©es\n",
    "        - importer le dataset\n",
    "        - scinder en train, validation, test\n",
    "        - normaliser\n",
    "    2. Cr√©ation d'une fonction de co√ªt m√©tier\n",
    "    3. Fonction pour impl√©menter un mod√®le et l'√©valuer (tracking MLflow)\n",
    "    4. Simulation des mod√®les"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pr√©parer les donn√©es du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Importer le dataset --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset train cr√©√© pr√©c√©dement, l'entrainement et la selection du mod√®le se fera uniquement sur ce dataset\n",
    "data = pd.read_csv('./data/train_small.csv')\n",
    "# data = pd.read_csv('./data/train_light.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Scinder le dataset --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ids\n",
    "data_ids = data['SK_ID_CURR']\n",
    "    \n",
    "# Extract the labels for training\n",
    "labels = data['TARGET']\n",
    "    \n",
    "# Remove the ids and target\n",
    "X = data.drop(columns = ['SK_ID_CURR', 'TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©parons nos donn√©es en entrainement et test\n",
    "# Tout d'abord, nous divisons les donn√©es en jeu d'entra√Ænement et jeu temporaire (ensemble de test + validation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, stratify=labels, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions dataset X_train, y_train :  (215257, 276) (215257,)\n",
      "Dimensions dataset X_test, y_test :  (92254, 276) (92254,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions dataset X_train, y_train : \", X_train.shape, y_train.shape)\n",
    "print(\"Dimensions dataset X_test, y_test : \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Normaliser les donn√©es --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cr√©ation d'une fonction de co√ªt m√©tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP : true positive, vrai positif : √©chantillons positifs pr√©dits comme positifs.\n",
    "# FP : false positive, faux positif : √©chantillons n√©gatifs pr√©dits comme positifs de fa√ßon erron√©e.\n",
    "# TN : true negative, vrai n√©gatif : √©chantillons n√©gatifs pr√©dits comme n√©gatifs.\n",
    "# FN : false negative, faux n√©gatif : √©chantillons positifs pr√©dits comme n√©gatifs de fa√ßon erron√©e.\n",
    "# Le rappel = TP / (TP + FN) (recall en anglais) est adapt√© pour minimiser les faux n√©gatifs.\n",
    "\n",
    "def cout_metier(y_true, y_pred):\n",
    "    \"\"\"Cette fonction calcule le co√ªt m√©tier √† partir de la matrice de confusion : 10*FN + FP.\"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel() # Je dois mettre y_proba ici ??? (pour prendre en compte le seuil)\n",
    "    return 10 * fn + fp\n",
    "\n",
    "cout_metier_scorer = make_scorer(cout_metier, greater_is_better=False)\n",
    "\n",
    "def find_best_threshold(estimator, X, y):\n",
    "    \"\"\"Cette fonction trouve le seuil optimal en testant une gamme de seuils et en choisissant celui avec le score m√©tier le plus bas.\"\"\"\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "    best_threshold, best_score = 0, float('inf')\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (estimator.predict_proba(X)[:, 1] >= threshold).astype(int)\n",
    "        score = cout_metier(y, y_pred)\n",
    "        if score < best_score:\n",
    "            best_threshold, best_score = threshold, score\n",
    "    return best_threshold, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fonction pour impl√©menter un mod√®le et l'√©valuer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire une fonction pour d√©finir un mod√®le, tester les hyper-param√®tres par validation crois√©e, \n",
    "# entrainer le modele choisi et √©valuer les indicateurs de performance du mod√®le\n",
    "\n",
    "def modele_classification(estimator, parametres, folds, X1, y1, X2, y2, experiment_name=\"MLflow Classification Experiment\"):\n",
    "    \"\"\"\n",
    "    Renvoie le r√©sultat du mod√®le avec les principaux indicateurs de performance pour la classification binaire\n",
    "    0. X1, y1 = train set - X2, y2 = validation set\n",
    "    1. R√©√©quilibrer les classes avec SMOTE\n",
    "    2. D√©finition du mod√®le avec la liste de param√®tres √† tester\n",
    "    3. Entrainement du mod√®le sur le train \n",
    "    4. Les meilleurs param√®tres du mod√®le\n",
    "    5. Le co√ªt m√©tier du mod√®le sur le train\n",
    "    6. Calculer l'AUC du train \"cross-valid√©\"\n",
    "    6. Pr√©dictions pour X_test, scores sur le test et calcul des m√©triques\n",
    "    7. Temps d'entrainement et predict du mod√®le\n",
    "    8. MLflow tracking\n",
    "    9. Stockage de la courbe ROC\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. R√©√©quilibrer les classes avec SMOTE\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('sampling', SMOTE()),\n",
    "        ('classification', estimator)\n",
    "    ])\n",
    "    \n",
    "    # 2. D√©finition du mod√®le avec la liste de param√®tres √† tester\n",
    "    modele = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=parametres,\n",
    "        cv=folds,\n",
    "        scoring={'co√ªt_m√©tier': cout_metier_scorer, 'roc_auc': 'roc_auc', 'accuracy': 'accuracy'},\n",
    "        refit='co√ªt_m√©tier'  # Optimiser selon notre co√ªt m√©tier\n",
    "    )\n",
    "    \n",
    "    # 3. Entrainement du mod√®le sur le jeu d'entra√Ænement\n",
    "    modele.fit(X1, y1)\n",
    "    \n",
    "    # 4. Les meilleurs param√®tres du mod√®le\n",
    "    best_params = modele.best_params_\n",
    "    print(f\"Les meilleurs param√®tres du mod√®le sont : {best_params}\")\n",
    "    \n",
    "    # 5. Le co√ªt m√©tier du mod√®le sur le train\n",
    "    best_cost = -modele.best_score_  # On a mis le scoring pour que plus petit soit mieux, donc le meilleur score est n√©gatif\n",
    "    print(f\"Co√ªt m√©tier sur le train : {best_cost}\")\n",
    "\n",
    "    # 6. Calculer l'AUC du train \"cross-valid√©\"\n",
    "    auc_train_scores = cross_val_score(pipeline, X1, y1, cv=folds, scoring='roc_auc')\n",
    "    mean_auc_train = auc_train_scores.mean()\n",
    "    std_auc_train = auc_train_scores.std()\n",
    "    print(f\"AUC train (cross-valid√©) : {mean_auc_train:.4f} ¬± {std_auc_train:.4f}\")\n",
    "    \n",
    "    # 7. Trouver le seuil optimal\n",
    "    best_threshold, best_threshold_score = find_best_threshold(modele.best_estimator_, X2, y2)\n",
    "    print(f\"Seuil optimal : {best_threshold} avec un score m√©tier de : {best_threshold_score}\")\n",
    "    \n",
    "    # Pr√©dictions pour X_test et calcul des m√©triques pour identifier le meilleur mod√®le\n",
    "    y_proba = modele.predict_proba(X2)[:, 1]\n",
    "    y_pred = (y_proba >= best_threshold).astype(int)\n",
    "    \n",
    "    auc_test = roc_auc_score(y2, y_proba)\n",
    "    cout_metier_test = cout_metier(y2, y_pred)\n",
    "    f1_test = f1_score(y2, y_pred)\n",
    "    accuracy_test = accuracy_score(y2, y_pred)\n",
    "\n",
    "    print(f\"Co√ªt m√©tier test : {cout_metier_test}\")\n",
    "    print(f\"Score AUC test : {auc_test}\")\n",
    "    print(f\"F1-score test : {f1_test}\")\n",
    "    print(f\"Accuracy test : {accuracy_test}\")\n",
    "\n",
    "    # 8. Temps d'entrainement du mod√®le :\n",
    "    temps_moyen_ajustement = modele.cv_results_['mean_fit_time'][modele.best_index_]\n",
    "    print(\"Temps moyen d'ajustement du meilleur mod√®le (secondes):\", temps_moyen_ajustement)\n",
    "    # Temps Predict du mod√®le\n",
    "    temps_moyen_inference = modele.cv_results_['mean_score_time'][modele.best_index_]\n",
    "    print(\"Temps moyen d'inf√©rence du meilleur mod√®le (secondes):\", temps_moyen_inference)\n",
    "\n",
    "    # 8. MLflow tracking\n",
    "    mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\") # mlflow server --host 127.0.0.1 --port 8080 --> √† lancer dans Anaconda Prompt\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Log the hyperparameters\n",
    "        mlflow.log_params(best_params)\n",
    "\n",
    "        # Log the metrics\n",
    "        mlflow.log_metric(\"co√ªt_m√©tier_train\", best_cost)\n",
    "        mlflow.log_metric(\"AUC_train_cross_valid√©\", mean_auc_train)\n",
    "        mlflow.log_metric(\"co√ªt_m√©tier_test\", cout_metier_test)\n",
    "        mlflow.log_metric(\"auc_test\", auc_test)\n",
    "        mlflow.log_metric(\"f1_test\", f1_test)\n",
    "        mlflow.log_metric(\"accuracy_test\", accuracy_test)\n",
    "        mlflow.log_metric(\"best_threshold\", best_threshold)\n",
    "        mlflow.log_metric(\"mean_fit_time\", temps_moyen_ajustement)\n",
    "        mlflow.log_metric(\"mean_score_time\", temps_moyen_inference)\n",
    "        \n",
    "        # 9. Stockage de la courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y2, y_proba)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_test)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(\"roc_curve.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Log the ROC curve as an artifact\n",
    "        mlflow.log_artifact(\"roc_curve.png\")\n",
    "        \n",
    "        # Set a tag for context\n",
    "        mlflow.set_tag(\"Training Info\", \"Model training and evaluation for binary classification with custom cost function\")\n",
    "\n",
    "        # Infer the model signature\n",
    "        signature = infer_signature(X1, modele.predict(X1))\n",
    "        \n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=modele.best_estimator_,\n",
    "            artifact_path=\"model\",\n",
    "            signature=signature,\n",
    "            input_example=X1[:10],\n",
    "            registered_model_name=experiment_name\n",
    "        )\n",
    "\n",
    "    return modele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Simulation des mod√®les"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- DummyClassifier --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs param√®tres du mod√®le sont : {'classification__strategy': 'most_frequent'}\n",
      "Co√ªt m√©tier sur le train : 34754.0\n",
      "AUC train (cross-valid√©) : 0.5000 ¬± 0.0000\n",
      "Seuil optimal : 0.01 avec un score m√©tier de : 74480\n",
      "Co√ªt m√©tier test : 74480\n",
      "Score AUC test : 0.5\n",
      "F1-score test : 0.0\n",
      "Accuracy test : 0.9192663732737876\n",
      "Temps moyen d'ajustement du meilleur mod√®le (secondes): 7.2784429550170895\n",
      "Temps moyen d'inf√©rence du meilleur mod√®le (secondes): 0.29339118003845216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Dummy Classifier'.\n",
      "2024/08/08 14:31:39 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Dummy Classifier, version 1\n",
      "Created version '1' of model 'Dummy Classifier'.\n",
      "2024/08/08 14:31:49 INFO mlflow.tracking._tracking_service.client: üèÉ View run lyrical-midge-331 at: http://127.0.0.1:8080/#/experiments/231586947694154330/runs/f9300b22063e4538825ab6f9725531fe.\n",
      "2024/08/08 14:31:49 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/231586947694154330.\n"
     ]
    }
   ],
   "source": [
    "# D√©finir les param√®tres pour DummyClassifier\n",
    "parametres = {\n",
    "    'classification__strategy': ['most_frequent'] # ['most_frequent', 'stratified', 'uniform']\n",
    "}\n",
    "\n",
    "# Appeler la fonction avec un DummyClassifier\n",
    "modele_Dummyclassif = modele_classification(\n",
    "    estimator=DummyClassifier(),\n",
    "    parametres=parametres,\n",
    "    folds=5,\n",
    "    X1=X_train,\n",
    "    y1=y_train,\n",
    "    X2=X_test,\n",
    "    y2=y_test,\n",
    "    experiment_name=\"Dummy Classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Light GBM --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs param√®tres du mod√®le sont : {'classification__boosting_type': 'gbdt', 'classification__class_weight': 'balanced', 'classification__learning_rate': 0.001, 'classification__n_estimators': 100, 'classification__objective': 'binary', 'classification__verbose': -1}\n",
      "Co√ªt m√©tier sur le train : 32754.6\n",
      "AUC train (cross-valid√©) : 0.7654 ¬± 0.0017\n",
      "Seuil optimal : 0.48 avec un score m√©tier de : 62431\n",
      "Co√ªt m√©tier test : 62431\n",
      "Score AUC test : 0.6535151052279731\n",
      "F1-score test : 0.20540144339197114\n",
      "Accuracy test : 0.6944739523489496\n",
      "Temps moyen d'ajustement du meilleur mod√®le (secondes): 15.611072969436645\n",
      "Temps moyen d'inf√©rence du meilleur mod√®le (secondes): 0.5034257411956787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'LightGBM Classification'.\n",
      "2024/08/08 22:44:24 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LightGBM Classification, version 1\n",
      "Created version '1' of model 'LightGBM Classification'.\n",
      "2024/08/08 22:44:29 INFO mlflow.tracking._tracking_service.client: üèÉ View run polite-wren-23 at: http://127.0.0.1:8080/#/experiments/159117267029944621/runs/90eda313afbf4ba08f3a5a5c4d5c210c.\n",
      "2024/08/08 22:44:29 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/159117267029944621.\n"
     ]
    }
   ],
   "source": [
    "# D√©finir les param√®tres pour LightGBM\n",
    "parametres = {\n",
    "    'classification__objective': ['binary'], \n",
    "    'classification__boosting_type': ['gbdt'],\n",
    "    'classification__n_estimators': [100, 500, 1000], # [500, 1000]\n",
    "    'classification__learning_rate': [0.001,0.01,0.1], # [0.001,0.01,0.1]\n",
    "    'classification__class_weight': ['balanced'],\n",
    "    'classification__verbose': [-1]\n",
    "    }\n",
    "\n",
    "modele_LGBM = modele_classification(\n",
    "    estimator=lgb.LGBMClassifier(),\n",
    "    parametres=parametres,\n",
    "    folds=5,\n",
    "    X1=X_train,\n",
    "    y1=y_train,\n",
    "    X2=X_test,\n",
    "    y2=y_test,\n",
    "    experiment_name=\"LightGBM Classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- SMOTE pour r√©√©quilibrer les classes -- Finalement int√©gr√© directement dans le pipeline\n",
    "# Appliquer SMOTE pour g√©n√©rer des sample de la classe minoritaire\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- RandomForestClassifier --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs param√®tres du mod√®le sont : {'classification__class_weight': 'balanced', 'classification__max_depth': 10, 'classification__min_samples_split': 50, 'classification__n_estimators': 50}\n",
      "Co√ªt m√©tier sur le train : 29666.6\n",
      "AUC train (cross-valid√©) : 0.7199 ¬± 0.0024\n",
      "Seuil optimal : 0.34 avec un score m√©tier de : 57775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/08 17:30:43 INFO mlflow.tracking.fluent: Experiment with name 'Random Forest Classifier' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co√ªt m√©tier test : 57775\n",
      "Score AUC test : 0.6894636749502427\n",
      "F1-score test : 0.22282317399990254\n",
      "Accuracy test : 0.6542155353697401\n",
      "Temps moyen d'ajustement du meilleur mod√®le (secondes): 208.20021142959595\n",
      "Temps moyen d'inf√©rence du meilleur mod√®le (secondes): 1.1513511180877685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Random Forest Classifier'.\n",
      "2024/08/08 17:30:53 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random Forest Classifier, version 1\n",
      "Created version '1' of model 'Random Forest Classifier'.\n",
      "2024/08/08 17:31:03 INFO mlflow.tracking._tracking_service.client: üèÉ View run skittish-snipe-974 at: http://127.0.0.1:8080/#/experiments/902696018392126106/runs/c3355cb5bcde442ab7f263f136dfacb0.\n",
      "2024/08/08 17:31:03 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/902696018392126106.\n"
     ]
    }
   ],
   "source": [
    "# D√©finir les param√®tres\n",
    "parametres = {\n",
    "    'classification__n_estimators': [50, 100, 500], # [50, 100]\n",
    "    'classification__max_depth': [5, 10, 20], # [3, 5, 10]\n",
    "    'classification__min_samples_split': [30, 50, 100], # [2, 5, 10]\n",
    "    'classification__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "modele_RFclassif = modele_classification(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    parametres=parametres,\n",
    "    folds=5,\n",
    "    X1=X_train,\n",
    "    y1=y_train,\n",
    "    X2=X_test,\n",
    "    y2=y_test,\n",
    "    experiment_name=\"Random Forest Classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- LogisticRegression --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs param√®tres du mod√®le sont : {'classification__C': 0.1, 'classification__class_weight': 'balanced'}\n",
      "Co√ªt m√©tier sur le train : 22840.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC train (cross-valid√©) : 0.7563 ¬± 0.0029\n",
      "Seuil optimal : 0.54 avec un score m√©tier de : 49680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/08 17:47:47 INFO mlflow.tracking.fluent: Experiment with name 'Logistic Regression' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co√ªt m√©tier test : 49680\n",
      "Score AUC test : 0.7523182372667683\n",
      "F1-score test : 0.2774678632064031\n",
      "Accuracy test : 0.7416697378975438\n",
      "Temps moyen d'ajustement du meilleur mod√®le (secondes): 16.164799165725707\n",
      "Temps moyen d'inf√©rence du meilleur mod√®le (secondes): 0.43104114532470705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Logistic Regression'.\n",
      "2024/08/08 17:47:55 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic Regression, version 1\n",
      "Created version '1' of model 'Logistic Regression'.\n",
      "2024/08/08 17:48:04 INFO mlflow.tracking._tracking_service.client: üèÉ View run omniscient-shrew-234 at: http://127.0.0.1:8080/#/experiments/787584366056825571/runs/618b5c2422fc434ea9d4c31e3f5bb308.\n",
      "2024/08/08 17:48:04 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/787584366056825571.\n"
     ]
    }
   ],
   "source": [
    "# D√©finir les param√®tres\n",
    "parametres = {\n",
    "    'classification__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classification__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "modele_logRegression = modele_classification(\n",
    "    estimator=LogisticRegression(),\n",
    "    parametres=parametres,\n",
    "    folds=5,\n",
    "    X1=X_train,\n",
    "    y1=y_train,\n",
    "    X2=X_test,\n",
    "    y2=y_test,\n",
    "    experiment_name=\"Logistic Regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- DecisionTreeClassifier --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs param√®tres du mod√®le sont : {'classification__class_weight': 'balanced', 'classification__max_depth': 5, 'classification__min_samples_split': 50}\n",
      "Co√ªt m√©tier sur le train : 28811.6\n",
      "AUC train (cross-valid√©) : 0.5400 ¬± 0.0012\n",
      "Seuil optimal : 0.26 avec un score m√©tier de : 62301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/08 19:51:22 INFO mlflow.tracking.fluent: Experiment with name 'Decision Tree Classifier' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co√ªt m√©tier test : 62301\n",
      "Score AUC test : 0.6365774062254123\n",
      "F1-score test : 0.2004372389012749\n",
      "Accuracy test : 0.5995945975242266\n",
      "Temps moyen d'ajustement du meilleur mod√®le (secondes): 32.86524896621704\n",
      "Temps moyen d'inf√©rence du meilleur mod√®le (secondes): 0.3423666000366211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Decision Tree Classifier'.\n",
      "2024/08/08 19:51:25 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Decision Tree Classifier, version 1\n",
      "Created version '1' of model 'Decision Tree Classifier'.\n",
      "2024/08/08 19:51:30 INFO mlflow.tracking._tracking_service.client: üèÉ View run bold-asp-485 at: http://127.0.0.1:8080/#/experiments/780877098331849492/runs/5b4df5ae621c4e6a94207c7dfcf01855.\n",
      "2024/08/08 19:51:30 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/780877098331849492.\n"
     ]
    }
   ],
   "source": [
    "# D√©finir les param√®tres\n",
    "parametres = {\n",
    "    'classification__max_depth': [5, 10, 20], \n",
    "    'classification__min_samples_split': [30, 50, 100],\n",
    "    'classification__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "modele_logRegression = modele_classification(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    \n",
    "    parametres=parametres,\n",
    "    folds=5,\n",
    "    X1=X_train,\n",
    "    y1=y_train,\n",
    "    X2=X_test,\n",
    "    y2=y_test,\n",
    "    experiment_name=\"Decision Tree Classifier\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel Formation_P7",
   "language": "python",
   "name": "formation_p7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
