{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet P7 : Implémentez un modèle de scoring - Modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous êtes Data Scientist au sein d'une société financière, nommée \"Prêt à dépenser\", qui propose des crédits à la consommation pour des personnes ayant peu ou pas du tout d'historique de prêt.\n",
    "\n",
    "L’entreprise souhaite mettre en œuvre un outil de “scoring crédit” pour calculer la probabilité qu’un client rembourse son crédit, puis classifie la demande en crédit accordé ou refusé. Elle souhaite donc développer un algorithme de classification en s’appuyant sur des sources de données variées (données comportementales, données provenant d'autres institutions financières, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> MISSION 1 : </b>\n",
    "\n",
    "Construire un modèle de scoring qui donnera une prédiction sur la probabilité de faillite d'un client de façon automatique.\n",
    "\n",
    "Analyser les features qui contribuent le plus au modèle, d’une manière générale (feature importance globale) et au niveau d’un client (feature importance locale), afin, dans un soucis de transparence, de permettre à un chargé d’études de mieux comprendre le score attribué par le modèle.\n",
    "\n",
    "Mettre en production le modèle de scoring de prédiction à l’aide d’une API et réaliser une interface de test de cette API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Approche MLOps : </b>\n",
    "\n",
    "Afin de pouvoir faire évoluer régulièrement le modèle, mettre en œuvre une démarche de type MLOps d’automatisation et d’industrialisation de la gestion du cycle de vie du modèle (du tracking des expérimentations à l’analyse en production du data drift). \n",
    "\n",
    "Mettre en oeuvre au minimum les étapes orientées MLOps suivantes : \n",
    "\n",
    "- Dans le notebook d’entraînement des modèles, générer à l’aide de MLFlow un tracking d'expérimentations\n",
    "- Lancer l’interface web 'UI MLFlow\" d'affichage des résultats du tracking\n",
    "- Réaliser avec MLFlow un stockage centralisé des modèles dans un “model registry”\n",
    "- Tester le serving MLFlow\n",
    "- Gérer le code avec le logiciel de version Git\n",
    "- Partager le code sur Github pour assurer une intégration continue\n",
    "- Utiliser Github Actions pour le déploiement continu et automatisé du code de l’API sur le cloud\n",
    "- Concevoir des tests unitaires avec Pytest (ou Unittest) et les exécuter de manière automatisée lors du build réalisé par Github Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Elaboration du modèle : </b>\n",
    "\n",
    "Attention à deux points spécifiques au contexte métier : \n",
    "\n",
    "- Le déséquilibre entre le nombre de bons et de moins bons clients doit être pris en compte pour élaborer un modèle pertinent, avec une méthode au choix\n",
    "- Le déséquilibre du coût métier entre un faux négatif (FN - mauvais client prédit bon client : donc crédit accordé et perte en capital) et un faux positif (FP - bon client prédit mauvais : donc refus crédit et manque à gagner en marge). Vous pourrez supposer, par exemple, que le coût d’un FN est dix fois supérieur au coût d’un FP. Vous créerez un score “métier” (minimisation du coût d’erreur de prédiction des FN et FP) pour comparer les modèles, afin de choisir le meilleur modèle et ses meilleurs hyperparamètres. Attention cette minimisation du coût métier doit passer par l’optimisation du seuil qui détermine, à partir d’une probabilité, la classe 0 ou 1 (un “predict” suppose un seuil à 0.5 qui n’est pas forcément l’optimum). En parallèle, maintenez pour comparaison et contrôle des mesures plus techniques, telles que l’AUC et l’accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernels Kaggle utilisés pour l’analyse exploratoire, la préparation des données et le feature engineering :\n",
    "    \n",
    "    - https://www.kaggle.com/code/willkoehrsen/start-here-a-gentle-introduction/notebook\n",
    "    - https://www.kaggle.com/code/willkoehrsen/introduction-to-manual-feature-engineering\n",
    "    - https://www.kaggle.com/code/willkoehrsen/introduction-to-manual-feature-engineering-p2\n",
    "    - https://www.kaggle.com/code/willkoehrsen/introduction-to-feature-selection\n",
    "    \n",
    "    - https://www.kaggle.com/code/jsaguiar/lightgbm-with-simple-features/script --> pas utilisé pour le moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapes du projet :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elaboration d'un modèle de prédiction sous forme d’une API qui permet de calculer la probabilité de défaut du client, ainsi que sa classe (accepté ou refusé), déployer l'API sur une plateforme Cloud.\n",
    "\n",
    "- <b> Etape préliminaire : </b> Importation des données ( --> NoteBook1 : Preparation des données )\n",
    "- <b> Etape 1 : </b> EDA et feature engineering sur la table principale application ( --> NoteBook1 ) \n",
    "- <b> Etape 2 : </b> Ajout des tables bureau et bureau_balance ( --> NoteBook1 )\n",
    "- <b> Etape 3 : </b> Ajout des tables previous_application, POS_CASH_balance, installments_payments et credit_card_balance ( --> NoteBook1 )\n",
    "\n",
    "- <b> Etape 4 : </b> EDA et Feature selection, feature engineering ( --> NoteBook1 )\n",
    "\n",
    "- <b> Etape 5 : </b> Elaboration des modèles avec un tracking d'expérimentations (avec Cross-Validation et optimisation des hyperparamètres, via GridsearchCV ou équivalent)\n",
    "- <b> Etape 6 : </b> Création de l'API (Notebook ou une application Streamlit pour réaliser en local l’interface de test de l’API)\n",
    "- <b> Etape 7 : </b> Déploiement de l’API sur une plateforme Cloud (de préférence une solution gratuite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d632b08c-d252-4238-b496-e2c6edebec4b",
    "_uuid": "eb13bf76d4e1e60d0703856ec391cdc2c5bdf1fb"
   },
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn methods\n",
    "from sklearn.metrics import make_scorer, roc_curve, roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Données déséquilibrées\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Models\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Outils MLOps\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAPE 5 : Elaboration des modèles avec un tracking d'expérimentations\n",
    "\n",
    "ETAPE 5\n",
    "    \n",
    "    1. Préparer les données\n",
    "        - importer le dataset\n",
    "        - scinder en train, validation, test\n",
    "        - normaliser\n",
    "    2. Création d'une fonction de coût métier\n",
    "    3. Fonction pour implémenter un modèle et l'évaluer (tracking MLflow)\n",
    "    4. Simulation des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Préparer les données du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Importer le dataset --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset train créé précédement, l'entrainement et la selection du modèle se fera uniquement sur ce dataset\n",
    "data = pd.read_csv('./data/train_small.csv')\n",
    "# data = pd.read_csv('./data/train_light.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Scinder le dataset --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ids\n",
    "data_ids = data['SK_ID_CURR']\n",
    "    \n",
    "# Extract the labels for training\n",
    "labels = data['TARGET']\n",
    "    \n",
    "# Remove the ids and target\n",
    "X = data.drop(columns = ['SK_ID_CURR', 'TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparons nos données en entrainement et test\n",
    "# Tout d'abord, nous divisons les données en jeu d'entraînement et jeu temporaire (ensemble de test + validation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, stratify=labels, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions dataset X_train, y_train :  (215257, 276) (215257,)\n",
      "Dimensions dataset X_test, y_test :  (92254, 276) (92254,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions dataset X_train, y_train : \", X_train.shape, y_train.shape)\n",
    "print(\"Dimensions dataset X_test, y_test : \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Normaliser les données --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Création d'une fonction de coût métier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP : true positive, vrai positif : échantillons positifs prédits comme positifs.\n",
    "# FP : false positive, faux positif : échantillons négatifs prédits comme positifs de façon erronée.\n",
    "# TN : true negative, vrai négatif : échantillons négatifs prédits comme négatifs.\n",
    "# FN : false negative, faux négatif : échantillons positifs prédits comme négatifs de façon erronée.\n",
    "# Le rappel = TP / (TP + FN) (recall en anglais) est adapté pour minimiser les faux négatifs.\n",
    "\n",
    "def cout_metier(y_true, y_pred):\n",
    "    \"\"\"Cette fonction calcule le coût métier à partir de la matrice de confusion : 10*FN + FP.\"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel() # Je dois mettre y_proba ici ??? (pour prendre en compte le seuil)\n",
    "    return 10 * fn + fp\n",
    "\n",
    "cout_metier_scorer = make_scorer(cout_metier, greater_is_better=False)\n",
    "\n",
    "def find_best_threshold(estimator, X, y):\n",
    "    \"\"\"Cette fonction trouve le seuil optimal en testant une gamme de seuils et en choisissant celui avec le score métier le plus bas.\"\"\"\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "    best_threshold, best_score = 0, float('inf')\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (estimator.predict_proba(X)[:, 1] >= threshold).astype(int)\n",
    "        score = cout_metier(y, y_pred)\n",
    "        if score < best_score:\n",
    "            best_threshold, best_score = threshold, score\n",
    "    return best_threshold, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fonction pour implémenter un modèle et l'évaluer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire une fonction pour définir un modèle, tester les hyper-paramètres par validation croisée, \n",
    "# entrainer le modele choisi et évaluer les indicateurs de performance du modèle\n",
    "\n",
    "def modele_classification(estimator, parametres, folds, X1, y1, X2, y2, experiment_name=\"MLflow Classification Experiment\"):\n",
    "    \"\"\"\n",
    "    Renvoie le résultat du modèle avec les principaux indicateurs de performance pour la classification binaire\n",
    "    0. X1, y1 = train set - X2, y2 = validation set\n",
    "    1. Rééquilibrer les classes avec SMOTE\n",
    "    2. Définition du modèle avec la liste de paramètres à tester\n",
    "    3. Entrainement du modèle sur le train \n",
    "    4. Les meilleurs paramètres du modèle\n",
    "    5. Le coût métier du modèle sur le train\n",
    "    6. Calculer l'AUC du train \"cross-validé\"\n",
    "    6. Prédictions pour X_test, scores sur le test et calcul des métriques\n",
    "    7. Temps d'entrainement et predict du modèle\n",
    "    8. MLflow tracking\n",
    "    9. Stockage de la courbe ROC\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Rééquilibrer les classes avec SMOTE\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('sampling', SMOTE()),\n",
    "        ('classification', estimator)\n",
    "    ])\n",
    "    \n",
    "    # 2. Définition du modèle avec la liste de paramètres à tester\n",
    "    modele = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=parametres,\n",
    "        cv=folds,\n",
    "        scoring={'coût_métier': cout_metier_scorer, 'roc_auc': 'roc_auc', 'accuracy': 'accuracy'},\n",
    "        refit='coût_métier'  # Optimiser selon notre coût métier\n",
    "    )\n",
    "    \n",
    "    # 3. Entrainement du modèle sur le jeu d'entraînement\n",
    "    modele.fit(X1, y1)\n",
    "    \n",
    "    # 4. Les meilleurs paramètres du modèle\n",
    "    best_params = modele.best_params_\n",
    "    print(f\"Les meilleurs paramètres du modèle sont : {best_params}\")\n",
    "    \n",
    "    # 5. Le coût métier du modèle sur le train\n",
    "    best_cost = -modele.best_score_  # On a mis le scoring pour que plus petit soit mieux, donc le meilleur score est négatif\n",
    "    print(f\"Coût métier sur le train : {best_cost}\")\n",
    "\n",
    "    # 6. Calculer l'AUC du train \"cross-validé\"\n",
    "    auc_train_scores = cross_val_score(pipeline, X1, y1, cv=folds, scoring='roc_auc')\n",
    "    mean_auc_train = auc_train_scores.mean()\n",
    "    std_auc_train = auc_train_scores.std()\n",
    "    print(f\"AUC train (cross-validé) : {mean_auc_train:.4f} ± {std_auc_train:.4f}\")\n",
    "    \n",
    "    # 7. Trouver le seuil optimal\n",
    "    best_threshold, best_threshold_score = find_best_threshold(modele.best_estimator_, X2, y2)\n",
    "    print(f\"Seuil optimal : {best_threshold} avec un score métier de : {best_threshold_score}\")\n",
    "    \n",
    "    # Prédictions pour X_test et calcul des métriques pour identifier le meilleur modèle\n",
    "    y_proba = modele.predict_proba(X2)[:, 1]\n",
    "    y_pred = (y_proba >= best_threshold).astype(int)\n",
    "    \n",
    "    auc_test = roc_auc_score(y2, y_proba)\n",
    "    cout_metier_test = cout_metier(y2, y_pred)\n",
    "    f1_test = f1_score(y2, y_pred)\n",
    "    accuracy_test = accuracy_score(y2, y_pred)\n",
    "\n",
    "    print(f\"Coût métier test : {cout_metier_test}\")\n",
    "    print(f\"Score AUC test : {auc_test}\")\n",
    "    print(f\"F1-score test : {f1_test}\")\n",
    "    print(f\"Accuracy test : {accuracy_test}\")\n",
    "\n",
    "    # 8. Temps d'entrainement du modèle :\n",
    "    temps_moyen_ajustement = modele.cv_results_['mean_fit_time'][modele.best_index_]\n",
    "    print(\"Temps moyen d'ajustement du meilleur modèle (secondes):\", temps_moyen_ajustement)\n",
    "    # Temps Predict du modèle\n",
    "    temps_moyen_inference = modele.cv_results_['mean_score_time'][modele.best_index_]\n",
    "    print(\"Temps moyen d'inférence du meilleur modèle (secondes):\", temps_moyen_inference)\n",
    "\n",
    "    # 8. MLflow tracking\n",
    "    mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\") # mlflow server --host 127.0.0.1 --port 8080 --> à lancer dans Anaconda Prompt\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Log the hyperparameters\n",
    "        mlflow.log_params(best_params)\n",
    "\n",
    "        # Log the metrics\n",
    "        mlflow.log_metric(\"coût_métier_train\", best_cost)\n",
    "        mlflow.log_metric(\"AUC_train_cross_validé\", mean_auc_train)\n",
    "        mlflow.log_metric(\"coût_métier_test\", cout_metier_test)\n",
    "        mlflow.log_metric(\"auc_test\", auc_test)\n",
    "        mlflow.log_metric(\"f1_test\", f1_test)\n",
    "        mlflow.log_metric(\"accuracy_test\", accuracy_test)\n",
    "        mlflow.log_metric(\"best_threshold\", best_threshold)\n",
    "        mlflow.log_metric(\"mean_fit_time\", temps_moyen_ajustement)\n",
    "        mlflow.log_metric(\"mean_score_time\", temps_moyen_inference)\n",
    "        \n",
    "        # 9. Stockage de la courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y2, y_proba)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_test)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(\"roc_curve.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Log the ROC curve as an artifact\n",
    "        mlflow.log_artifact(\"roc_curve.png\")\n",
    "        \n",
    "        # Set a tag for context\n",
    "        mlflow.set_tag(\"Training Info\", \"Model training and evaluation for binary classification with custom cost function\")\n",
    "\n",
    "        # Infer the model signature\n",
    "        signature = infer_signature(X1, modele.predict(X1))\n",
    "        \n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=modele.best_estimator_,\n",
    "            artifact_path=\"model\",\n",
    "            signature=signature,\n",
    "            input_example=X1[:10],\n",
    "            registered_model_name=experiment_name\n",
    "        )\n",
    "\n",
    "    return modele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Simulation des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- DummyClassifier --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs paramètres du modèle sont : {'classification__strategy': 'most_frequent'}\n",
      "Coût métier sur le train : 34754.0\n",
      "AUC train (cross-validé) : 0.5000 ± 0.0000\n",
      "Seuil optimal : 0.01 avec un score métier de : 74480\n",
      "Coût métier test : 74480\n",
      "Score AUC test : 0.5\n",
      "F1-score test : 0.0\n",
      "Accuracy test : 0.9192663732737876\n",
      "Temps moyen d'ajustement du meilleur modèle (secondes): 7.2784429550170895\n",
      "Temps moyen d'inférence du meilleur modèle (secondes): 0.29339118003845216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Dummy Classifier'.\n",
      "2024/08/08 14:31:39 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Dummy Classifier, version 1\n",
      "Created version '1' of model 'Dummy Classifier'.\n",
      "2024/08/08 14:31:49 INFO mlflow.tracking._tracking_service.client: 🏃 View run lyrical-midge-331 at: http://127.0.0.1:8080/#/experiments/231586947694154330/runs/f9300b22063e4538825ab6f9725531fe.\n",
      "2024/08/08 14:31:49 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:8080/#/experiments/231586947694154330.\n"
     ]
    }
   ],
   "source": [
    "# Définir les paramètres pour DummyClassifier\n",
    "parametres = {\n",
    "    'classification__strategy': ['most_frequent'] # ['most_frequent', 'stratified', 'uniform']\n",
    "}\n",
    "\n",
    "# Appeler la fonction avec un DummyClassifier\n",
    "modele_Dummyclassif = modele_classification(\n",
    "    estimator=DummyClassifier(),\n",
    "    parametres=parametres,\n",
    "    folds=5,\n",
    "    X1=X_train,\n",
    "    y1=y_train,\n",
    "    X2=X_test,\n",
    "    y2=y_test,\n",
    "    experiment_name=\"Dummy Classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Light GBM --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs paramètres du modèle sont : {'classification__boosting_type': 'gbdt', 'classification__class_weight': 'balanced', 'classification__learning_rate': 0.001, 'classification__n_estimators': 100, 'classification__objective': 'binary', 'classification__verbose': -1}\n",
      "Coût métier sur le train : 32754.6\n",
      "AUC train (cross-validé) : 0.7654 ± 0.0017\n",
      "Seuil optimal : 0.48 avec un score métier de : 62431\n",
      "Coût métier test : 62431\n",
      "Score AUC test : 0.6535151052279731\n",
      "F1-score test : 0.20540144339197114\n",
      "Accuracy test : 0.6944739523489496\n",
      "Temps moyen d'ajustement du meilleur modèle (secondes): 15.611072969436645\n",
      "Temps moyen d'inférence du meilleur modèle (secondes): 0.5034257411956787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'LightGBM Classification'.\n",
      "2024/08/08 22:44:24 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LightGBM Classification, version 1\n",
      "Created version '1' of model 'LightGBM Classification'.\n",
      "2024/08/08 22:44:29 INFO mlflow.tracking._tracking_service.client: 🏃 View run polite-wren-23 at: http://127.0.0.1:8080/#/experiments/159117267029944621/runs/90eda313afbf4ba08f3a5a5c4d5c210c.\n",
      "2024/08/08 22:44:29 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:8080/#/experiments/159117267029944621.\n"
     ]
    }
   ],
   "source": [
    "# Définir les paramètres pour LightGBM\n",
    "parametres = {\n",
    "    'classification__objective': ['binary'], \n",
    "    'classification__boosting_type': ['gbdt'],\n",
    "    'classification__n_estimators': [100, 500, 1000], # [500, 1000]\n",
    "    'classification__learning_rate': [0.001,0.01,0.1], # [0.001,0.01,0.1]\n",
    "    'classification__class_weight': ['balanced'],\n",
    "    'classification__verbose': [-1]\n",
    "    }\n",
    "\n",
    "modele_LGBM = modele_classification(\n",
    "    estimator=lgb.LGBMClassifier(),\n",
    "    parametres=parametres,\n",
    "    folds=5,\n",
    "    X1=X_train,\n",
    "    y1=y_train,\n",
    "    X2=X_test,\n",
    "    y2=y_test,\n",
    "    experiment_name=\"LightGBM Classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- SMOTE pour rééquilibrer les classes -- Finalement intégré directement dans le pipeline\n",
    "# Appliquer SMOTE pour générer des sample de la classe minoritaire\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- RandomForestClassifier --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs paramètres du modèle sont : {'classification__class_weight': 'balanced', 'classification__max_depth': 10, 'classification__min_samples_split': 50, 'classification__n_estimators': 50}\n",
      "Coût métier sur le train : 29666.6\n",
      "AUC train (cross-validé) : 0.7199 ± 0.0024\n",
      "Seuil optimal : 0.34 avec un score métier de : 57775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/08 17:30:43 INFO mlflow.tracking.fluent: Experiment with name 'Random Forest Classifier' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coût métier test : 57775\n",
      "Score AUC test : 0.6894636749502427\n",
      "F1-score test : 0.22282317399990254\n",
      "Accuracy test : 0.6542155353697401\n",
      "Temps moyen d'ajustement du meilleur modèle (secondes): 208.20021142959595\n",
      "Temps moyen d'inférence du meilleur modèle (secondes): 1.1513511180877685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Random Forest Classifier'.\n",
      "2024/08/08 17:30:53 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random Forest Classifier, version 1\n",
      "Created version '1' of model 'Random Forest Classifier'.\n",
      "2024/08/08 17:31:03 INFO mlflow.tracking._tracking_service.client: 🏃 View run skittish-snipe-974 at: http://127.0.0.1:8080/#/experiments/902696018392126106/runs/c3355cb5bcde442ab7f263f136dfacb0.\n",
      "2024/08/08 17:31:03 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:8080/#/experiments/902696018392126106.\n"
     ]
    }
   ],
   "source": [
    "# Définir les paramètres\n",
    "parametres = {\n",
    "    'classification__n_estimators': [50, 100, 500], # [50, 100]\n",
    "    'classification__max_depth': [5, 10, 20], # [3, 5, 10]\n",
    "    'classification__min_samples_split': [30, 50, 100], # [2, 5, 10]\n",
    "    'classification__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "modele_RFclassif = modele_classification(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    parametres=parametres,\n",
    "    folds=5,\n",
    "    X1=X_train,\n",
    "    y1=y_train,\n",
    "    X2=X_test,\n",
    "    y2=y_test,\n",
    "    experiment_name=\"Random Forest Classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- LogisticRegression --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs paramètres du modèle sont : {'classification__C': 0.1, 'classification__class_weight': 'balanced'}\n",
      "Coût métier sur le train : 22840.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\druar\\anaconda3\\envs\\Formation_P7\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC train (cross-validé) : 0.7563 ± 0.0029\n",
      "Seuil optimal : 0.54 avec un score métier de : 49680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/08 17:47:47 INFO mlflow.tracking.fluent: Experiment with name 'Logistic Regression' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coût métier test : 49680\n",
      "Score AUC test : 0.7523182372667683\n",
      "F1-score test : 0.2774678632064031\n",
      "Accuracy test : 0.7416697378975438\n",
      "Temps moyen d'ajustement du meilleur modèle (secondes): 16.164799165725707\n",
      "Temps moyen d'inférence du meilleur modèle (secondes): 0.43104114532470705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Logistic Regression'.\n",
      "2024/08/08 17:47:55 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic Regression, version 1\n",
      "Created version '1' of model 'Logistic Regression'.\n",
      "2024/08/08 17:48:04 INFO mlflow.tracking._tracking_service.client: 🏃 View run omniscient-shrew-234 at: http://127.0.0.1:8080/#/experiments/787584366056825571/runs/618b5c2422fc434ea9d4c31e3f5bb308.\n",
      "2024/08/08 17:48:04 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:8080/#/experiments/787584366056825571.\n"
     ]
    }
   ],
   "source": [
    "# Définir les paramètres\n",
    "parametres = {\n",
    "    'classification__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classification__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "modele_logRegression = modele_classification(\n",
    "    estimator=LogisticRegression(),\n",
    "    parametres=parametres,\n",
    "    folds=5,\n",
    "    X1=X_train,\n",
    "    y1=y_train,\n",
    "    X2=X_test,\n",
    "    y2=y_test,\n",
    "    experiment_name=\"Logistic Regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- DecisionTreeClassifier --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs paramètres du modèle sont : {'classification__class_weight': 'balanced', 'classification__max_depth': 5, 'classification__min_samples_split': 50}\n",
      "Coût métier sur le train : 28811.6\n",
      "AUC train (cross-validé) : 0.5400 ± 0.0012\n",
      "Seuil optimal : 0.26 avec un score métier de : 62301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/08 19:51:22 INFO mlflow.tracking.fluent: Experiment with name 'Decision Tree Classifier' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coût métier test : 62301\n",
      "Score AUC test : 0.6365774062254123\n",
      "F1-score test : 0.2004372389012749\n",
      "Accuracy test : 0.5995945975242266\n",
      "Temps moyen d'ajustement du meilleur modèle (secondes): 32.86524896621704\n",
      "Temps moyen d'inférence du meilleur modèle (secondes): 0.3423666000366211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Decision Tree Classifier'.\n",
      "2024/08/08 19:51:25 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Decision Tree Classifier, version 1\n",
      "Created version '1' of model 'Decision Tree Classifier'.\n",
      "2024/08/08 19:51:30 INFO mlflow.tracking._tracking_service.client: 🏃 View run bold-asp-485 at: http://127.0.0.1:8080/#/experiments/780877098331849492/runs/5b4df5ae621c4e6a94207c7dfcf01855.\n",
      "2024/08/08 19:51:30 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:8080/#/experiments/780877098331849492.\n"
     ]
    }
   ],
   "source": [
    "# Définir les paramètres\n",
    "parametres = {\n",
    "    'classification__max_depth': [5, 10, 20], \n",
    "    'classification__min_samples_split': [30, 50, 100],\n",
    "    'classification__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "modele_logRegression = modele_classification(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    \n",
    "    parametres=parametres,\n",
    "    folds=5,\n",
    "    X1=X_train,\n",
    "    y1=y_train,\n",
    "    X2=X_test,\n",
    "    y2=y_test,\n",
    "    experiment_name=\"Decision Tree Classifier\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel Formation_P7",
   "language": "python",
   "name": "formation_p7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
